# KnowledgeDistillation - Hands On
A hand's on approach to learn how to do knowledge distillation on LLMs


## Introduction

Knowledge distillation is a technique in machine learning that involves transferring knowledge from one model (the teacher) to another model (the student) in order to improve the performance of the student model. This technique is particularly useful when the teacher model is larger and more complex than the student model, as it allows the student model to learn from the teacher's expertise.

In this README file, we will focus on knowledge distillation with a specific emphasis on the distillation loss. The distillation loss is a key component of knowledge distillation, and understanding its mathematical underpinnings is essential for implementing and customizing the knowledge distillation process.

## Background

### Teacher-Student Framework

Knowledge distillation typically involves a teacher model, often a complex and well-trained model, and a student model, which is usually simpler and computationally more efficient. The goal is to train the student model to mimic the behavior of the teacher model, effectively transferring the teacher's knowledge to the student.

### Soft Targets and Temperature

In knowledge distillation, we introduce the concept of "soft targets" to guide the student's learning. Instead of using the hard labels (one-hot encoded) for training data, we use soft probability distributions generated by the teacher model. These soft targets provide a more informative signal for the student to learn from.

Additionally, a temperature parameter is introduced to control the softness of these target distributions. A higher temperature results in softer distributions, and a lower temperature makes the distributions closer to one-hot encoding. The temperature parameter, denoted as "T," is usually a hyperparameter that can be tuned to balance the imitation of the teacher's predictions and the exploration of the student model.

## Distillation Loss

The distillation loss quantifies the difference between the student's predictions and the soft targets generated by the teacher model. It encourages the student to mimic the teacher's behavior by minimizing this loss during training. The distillation loss is often defined using the Kullback-Leibler (KL) divergence or Mean Squared Error (MSE). Here, we will focus on the KL divergence-based distillation loss.

### KL Divergence

The Kullback-Leibler (KL) divergence measures the difference between two probability distributions, P and Q. In the context of knowledge distillation, P represents the soft target distribution generated by the teacher, and Q represents the student's predicted distribution. The KL divergence from P to Q is defined as:

\[KL(P || Q) = \sum_{i} P(i) * log(\frac{P(i)}{Q(i)})\]

Where:
- \(P(i)\) is the probability assigned by the teacher for class \(i\).
- \(Q(i)\) is the probability predicted by the student for class \(i\).

### Distillation Loss Formulation

The distillation loss using KL divergence is typically defined as follows:

\[L_{\text{distill}} = T^2 * KL(\text{teacher's soft targets}, \text{student's predicted probabilities})\]

Where:
- \(T\) is the temperature parameter, as mentioned earlier.
- KL represents the Kullback-Leibler divergence.

The factor \(T^2\) is introduced to scale the effect of the temperature. It controls the balance between the imitation of the teacher and the exploration of the student. Smaller values of \(T\) make the loss more focused on closely matching the teacher's predictions.

## Implementation

To implement knowledge distillation with the distillation loss, you need to perform the following steps:

1. Train a teacher model on your dataset.
2. Generate soft targets using the teacher model for the same dataset.
3. Create a student model that is smaller and less complex than the teacher model.
4. Train the student model using the distillation loss as a part of the overall loss function.
5. Tune the hyperparameters, including the temperature parameter \(T\), to achieve the desired trade-off between accuracy and exploration.


For practical implementation details, see the attached notebook.
